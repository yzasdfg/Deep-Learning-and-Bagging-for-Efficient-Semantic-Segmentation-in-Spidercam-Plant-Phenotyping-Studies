{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae5cf9af-1ec3-4e05-bbe7-7d11603d892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os,json, cv2\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "from numpy.random import seed\n",
    "from numpy.random import randint\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt, random\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "from helper_func import *\n",
    "\n",
    "\n",
    "path = r'/home/yzstat/yzhan/Maize_images/'\n",
    "result_path=r'/work/yzstat/yzhan/Maize_images_MobilenetV2_keras/'\n",
    "\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27a06d5-4319-40c4-ac1a-2a45709be2c8",
   "metadata": {},
   "source": [
    "# Bagging prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c6dfdea-cbb3-4ff1-8801-0ed8e2772496",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_patch_list = sorted(glob.glob(path+ 'maize_image_patches/test/*.png'))\n",
    "image_list1=np.concatenate(([42], np.linspace(10, 290, 29)))\n",
    "\n",
    "import tensorflow as tf\n",
    "# test\n",
    "lr, batch_size = 0.001, 8\n",
    "H, W = 256, 256\n",
    "\n",
    "for n_estimator in [1, 5, 10, 15, 20, 30, 45, 60][:]:\n",
    "    print('n_estimator', n_estimator)\n",
    "    out_dir = result_path + 'Multiclass_Prediction/Predict_test_Patches_lr'+\\\n",
    "            str(lr)+'_0.5_batch'+str(batch_size)+'_rs50_750_n_estimator' +\\\n",
    "            str(int(n_estimator))\n",
    "    if not os.path.isdir(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "        print('Make directory')\n",
    "    \n",
    "    for file in test_image_patch_list[:]:\n",
    "        aggregated_predictions = np.zeros((H, W, 1), dtype=np.uint8)\n",
    "        filename = os.path.basename(file)\n",
    "        for image_seed in np.concatenate((image_list1, np.linspace(300, 330, 31)))[:n_estimator]:\n",
    "            #pred_test_dir='Multiclass_Prediction/Predict_test_Patches_lr0.001_0.5_batch16_rs50_is42_750'\n",
    "            pred_test_dir=result_path + 'Multiclass_Prediction/Predict_test_Patches_lr'+\\\n",
    "            str(lr)+'_0.5_batch'+str(batch_size)+'_rs50_is'+\\\n",
    "            str(int(image_seed))+'_750/'\n",
    "            pred_image = pred_test_dir + filename\n",
    "            img = tf.io.read_file(pred_image)\n",
    "            img= tf.image.decode_png(img, channels=1)\n",
    "            \n",
    "            aggregated_predictions += img\n",
    "\n",
    "\n",
    "        aggregated_predictions= np.array(np.round(aggregated_predictions/n_estimator), dtype=np.uint8)\n",
    "        tf.keras.preprocessing.image.save_img(os.path.join(out_dir, filename), aggregated_predictions, data_format=None, file_format='png', scale=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f56383-d592-4dee-88b2-9b57aa822897",
   "metadata": {},
   "source": [
    "# Bgging IoU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d351e3-e225-4ff3-93a3-4728cd58f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_val_size = '750'\n",
    "lr, batch_size = 0.001, 8\n",
    "H, W = 256, 256\n",
    "num_classes=2\n",
    "\n",
    "# Test IoU\n",
    "for n_estimator in [1, 5, 10, 15, 20, 30, 45, 60][:]:\n",
    "    print('n_estimator', n_estimator)\n",
    "    pred_test_dir ='Multiclass_Prediction/Predict_test_Patches_lr'+\\\n",
    "            str(lr)+'_0.5_batch'+str(batch_size)+'_rs50_750_n_estimator' +\\\n",
    "            str(int(n_estimator))\n",
    "    out_dir = result_path+ 'multiclass/iou_pkl_dropout_lr' + \\\n",
    "            str(lr)+'_0.5_batch' + str(batch_size)+ '_rs50_n_estimator'  +\\\n",
    "            str(int(n_estimator))\n",
    "    if not os.path.isdir(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "        print('Make directory')\n",
    "    test_image_patch_list = sorted(glob.glob(path+ r'maize_image_patches/test/*.png'))\n",
    "    mgray_list=[]\n",
    "\n",
    "    iou=[]\n",
    "    intersection, union = np.zeros(num_classes), np.zeros(num_classes)\n",
    "    all_mask, all_pred =np.array([]), np.array([])\n",
    "    inter_list, uni_list=[], []\n",
    "\n",
    "\n",
    "    pred_test_mask_patch_list=sorted(glob.glob(os.path.join(result_path+pred_test_dir, '*.png')))\n",
    "\n",
    "    test_mask_patch_list=sorted(glob.glob(path+'maize_label_patches/test/*.png'))\n",
    "\n",
    "    test_image_patch_files=[os.path.basename(file) for file in test_image_patch_list]\n",
    "\n",
    "    pred_test_mask_patch_files=[os.path.basename(file) for file in pred_test_mask_patch_list]\n",
    "    test_mask_patch_files=[os.path.basename(file) for file in test_mask_patch_list]\n",
    "    assert pred_test_mask_patch_files==test_mask_patch_files, 'pred, ground truth do not match.'\n",
    "    assert test_image_patch_files==test_mask_patch_files, 'image, mask do not match.'\n",
    "\n",
    "    print('pred test image size: ', len(pred_test_mask_patch_list))\n",
    "\n",
    "\n",
    "    for i in range(len(test_mask_patch_list)):\n",
    "        #print(i)\n",
    "        #assert os.path.basename(test_mask_patch_list[i])==os.path.basename(pred_mask_patch_list[i])\n",
    "\n",
    "        img=cv2.imread(test_image_patch_list[i], 0)\n",
    "        mgray_list.append(np.mean(img))\n",
    "\n",
    "        mask = tf.io.read_file(test_mask_patch_list[i])\n",
    "        mask= tf.image.decode_png(mask, channels=1)\n",
    "\n",
    "        y_pred=tf.io.read_file(pred_test_mask_patch_list[i])\n",
    "        y_pred= tf.image.decode_png(y_pred, channels=1)\n",
    "\n",
    "        iou.append(iou_dice(y_pred, mask, num_classes))\n",
    "\n",
    "        inter, uni=intersection_union(y_pred, mask, num_classes)\n",
    "        intersection, union=intersection+inter, union+uni\n",
    "\n",
    "        inter_list.append(inter)\n",
    "        uni_list.append(uni)\n",
    "\n",
    "        all_mask=np.append(all_mask, tf.reshape(mask, [-1]))\n",
    "        all_pred=np.append(all_pred, tf.reshape(y_pred, [-1]))\n",
    "\n",
    "\n",
    "    joblib.dump(iou, os.path.join(out_dir, 'test_' + train_val_size+'.pkl' ))\n",
    "    joblib.dump(mgray_list, os.path.join(out_dir, 'test_grayness.pkl' ))\n",
    "    gen_iou=intersection/union\n",
    "    joblib.dump(gen_iou, os.path.join(out_dir, 'test_gen_' + train_val_size+'.pkl' ))\n",
    "\n",
    "    joblib.dump(inter_list, os.path.join(out_dir, 'test_interaction_' + train_val_size+'.pkl' ))\n",
    "    joblib.dump(uni_list, os.path.join(out_dir, 'test_union_' + train_val_size+'.pkl' ))\n",
    "\n",
    "    cm_analysis(all_mask, all_pred, os.path.join(out_dir, 'test_cm_' + train_val_size+'.png'), save_file=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfe1fc3-67b8-4e76-ab42-4c28a70d75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_random_iou, all_random_iou2, all_random_miou, all_random_miou2=[], [], [], []\n",
    "\n",
    "lr, batch_size = 0.001, 8\n",
    "H, W = 256, 256\n",
    "x=[1, 5, 10, 15, 20, 30, 45, 60]\n",
    "#x=[str(int(xi)) for xi in x]\n",
    "print(x)\n",
    "size = 13\n",
    "start, end=0, len(x)\n",
    "\n",
    "#plt.subplots(figsize=(16, 4))\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14,4), sharey=True)\n",
    "\n",
    "left  = 0.1  # the left side of the subplots of the figure\n",
    "right = 0.9    # the right side of the subplots of the figure\n",
    "bottom = 0.1   # the bottom of the subplots of the figure\n",
    "top = 0.9      # the top of the subplots of the figure\n",
    "wspace = 0.3   # the amount of width reserved for blank space between subplots\n",
    "hspace = 0.2   # the amount of height reserved for white space between subplots\n",
    "\n",
    "\n",
    "plt.subplots_adjust(left=left,\n",
    "                    bottom=bottom, \n",
    "                    right=right, \n",
    "                    top=top, \n",
    "                    wspace=wspace, \n",
    "                    hspace=hspace)\n",
    "\n",
    "\n",
    "\n",
    "random_iou, random_mean_iou, = [], []\n",
    "\n",
    "# Test IoU\n",
    "for n_estimator in [1, 5, 10, 15, 20, 30, 45, 60][:]:\n",
    "    #r'multiclass/dropout_rate_active_learning_lr' + str(lr) + '_' +\\\n",
    "#    str(dropout_rate)+'_batch' + str(batch_size)+\\\n",
    "#'_select_ratio'+str(select_ratio)+'_rs'+str(seed)+'_is'+str(image_seed)\n",
    "    #iou_pkl_dropout_lr0.001_0.5_batch16_rs50_is42\n",
    "    \n",
    "    \n",
    "    iou_files=sorted(glob.glob(result_path+'multiclass/iou_pkl_dropout_lr'+str(lr)+\\\n",
    "                               '_0.5_batch'+str(batch_size)+'_rs50_n_estimator'  +\\\n",
    "                                str(int(n_estimator))+\n",
    "                              '//test_750.pkl'),\\\n",
    "                     key = lambda x: int(os.path.basename(x).split('_')[-1].split('.')[0])) \n",
    "    #print(iou_files)\n",
    "   \n",
    "    \n",
    "    for file in iou_files[:]:\n",
    "        \n",
    "        #print(os.path.basename(file))\n",
    "        filename=os.path.basename(file)\n",
    "\n",
    "\n",
    "        #print(os.path.basename(file))\n",
    "        if image_seed ==42: \n",
    "            print('random')\n",
    "            print(os.path.basename(file))\n",
    "\n",
    "        iou=joblib.load(file) #all image patch iou of one model prediction\n",
    "        #print(file)\n",
    "        \n",
    "        iou=np.nanmean(iou, axis=0) #dim:2, Iou0, iou for that one model prediction\n",
    "        #print(iou)\n",
    "        random_iou.append(iou)\n",
    "\n",
    "        mean_iou=np.nanmean(iou) #mean iou: miou\n",
    "        random_mean_iou.append(mean_iou)\n",
    "        miou=np.mean(mean_iou)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    axs[i].yaxis.set_tick_params(labelbottom=True, labelsize=size)\n",
    "    axs[i].plot(x[start: end], np.array(random_iou)[start: end, i], label='random_lr'+\\\n",
    "                str(lr)+'_batch'+str(batch_size))\n",
    "    \n",
    "    axs[i].set_ylabel('IoU$_{}$'.format(i), fontsize = size )\n",
    "    axs[i].set_xlabel('number of estimators', fontsize=size)\n",
    "    axs[i].set_xticks(x[start: end])\n",
    "    axs[i].set_xticklabels(x[start: end], rotation =90,fontsize=size)\n",
    "\n",
    "    axs[i].set_ylim(0.62, 0.73)\n",
    "\n",
    "    #plt.show()\n",
    "\n",
    "#plt.subplot(155)\n",
    "axs[-1].yaxis.set_tick_params(labelbottom=True, labelsize=size)\n",
    "axs[-1].plot(x[start: end], np.array(random_mean_iou)[start: end])#, label='random_lr'+str(lr)+'_batch'+str(batch_size))\n",
    "\n",
    "\n",
    "   \n",
    "axs[-1].set_ylabel('mIoU', fontsize = size )\n",
    "axs[-1].set_xlabel('sample size', fontsize=size)\n",
    "axs[-1].set_xticks(x[start: end])\n",
    "axs[-1].set_xticklabels(x[start: end], rotation =90, fontsize=size)\n",
    "plt.savefig(result_path+'/multiclass/bagging.png', bbox_inches='tight', dpi=600)\n",
    "#plt.savefig(result_path+'/Multiclass/visualization/test_iou_full.png', bbox_inches='tight', dpi=600)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da9616-7152-45ea-896a-8ffd234f5a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
